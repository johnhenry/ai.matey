{
  "metadata": {
    "provider": "openai",
    "scenario": "low-temperature",
    "model": "gpt-4",
    "capturedAt": "2025-10-26T13:30:00.000Z",
    "description": "Deterministic response with low temperature",
    "tags": ["chat", "deterministic", "low-temp", "gpt-4"],
    "apiVersion": "v1"
  },
  "request": {
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "What is 15 * 23?"
          }
        ]
      }
    ],
    "parameters": {
      "model": "gpt-4",
      "temperature": 0.0,
      "maxTokens": 50
    },
    "metadata": {
      "requestId": "fixture-low-temp-1",
      "timestamp": 1729949400000
    }
  },
  "response": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "type": "text",
          "text": "15 * 23 = 345"
        }
      ]
    },
    "usage": {
      "promptTokens": 10,
      "completionTokens": 8,
      "totalTokens": 18
    },
    "finishReason": "stop",
    "metadata": {
      "requestId": "fixture-low-temp-1",
      "timestamp": 1729949400600,
      "provenance": {
        "backend": "openai",
        "model": "gpt-4-0613",
        "adaptedAt": 1729949400600
      }
    }
  }
}
