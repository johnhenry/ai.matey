"use strict";(globalThis.webpackChunkai_matey_docs=globalThis.webpackChunkai_matey_docs||[]).push([[74],{1184:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var r=t(4041);const s={},i=r.createContext(s);function a(e){const n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(i.Provider,{value:n},e.children)}},8143:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"contributing/architecture","title":"Architecture Guide","description":"Deep dive into ai.matey\'s architecture, design patterns, and implementation details.","source":"@site/docs/contributing/architecture.md","sourceDirName":"contributing","slug":"/contributing/architecture","permalink":"/ai.matey/contributing/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/johnhenry/ai.matey/tree/main/packages/ai.matey.docs/docs/contributing/architecture.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"docs","previous":{"title":"Development Guide","permalink":"/ai.matey/contributing/development"}}');var s=t(1085),i=t(1184);const a={sidebar_position:3},o="Architecture Guide",c={},d=[{value:"Core Concepts",id:"core-concepts",level:2},{value:"The Universal Adapter Pattern",id:"the-universal-adapter-pattern",level:3},{value:"Intermediate Representation (IR)",id:"intermediate-representation-ir",level:2},{value:"Design Principles",id:"design-principles",level:3},{value:"IR Message Format",id:"ir-message-format",level:3},{value:"IR Request Format",id:"ir-request-format",level:3},{value:"IR Response Format",id:"ir-response-format",level:3},{value:"Frontend Adapters",id:"frontend-adapters",level:2},{value:"Interface",id:"interface",level:3},{value:"Implementation Example",id:"implementation-example",level:3},{value:"Backend Adapters",id:"backend-adapters",level:2},{value:"Interface",id:"interface-1",level:3},{value:"Implementation Example",id:"implementation-example-1",level:3},{value:"Bridge Architecture",id:"bridge-architecture",level:2},{value:"Core Implementation",id:"core-implementation",level:3},{value:"Router Architecture",id:"router-architecture",level:2},{value:"Core Implementation",id:"core-implementation-1",level:3},{value:"Middleware System",id:"middleware-system",level:2},{value:"Middleware Interface",id:"middleware-interface",level:3},{value:"Implementation Example",id:"implementation-example-2",level:3},{value:"Middleware Chain Execution",id:"middleware-chain-execution",level:3},{value:"Streaming Architecture",id:"streaming-architecture",level:2},{value:"Streaming Flow",id:"streaming-flow",level:3},{value:"Stream Consumption",id:"stream-consumption",level:3},{value:"Type System",id:"type-system",level:2},{value:"Type Hierarchy",id:"type-hierarchy",level:3},{value:"Type Safety",id:"type-safety",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Error Hierarchy",id:"error-hierarchy",level:3},{value:"Error Propagation",id:"error-propagation",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Async Iterator Efficiency",id:"async-iterator-efficiency",level:3},{value:"Middleware Performance",id:"middleware-performance",level:3},{value:"Testing Architecture",id:"testing-architecture",level:2},{value:"Mock Adapters",id:"mock-adapters",level:3},{value:"Integration Tests",id:"integration-tests",level:3},{value:"Design Patterns Used",id:"design-patterns-used",level:2},{value:"Next Steps",id:"next-steps",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"architecture-guide",children:"Architecture Guide"})}),"\n",(0,s.jsx)(n.p,{children:"Deep dive into ai.matey's architecture, design patterns, and implementation details."}),"\n",(0,s.jsx)(n.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsx)(n.h3,{id:"the-universal-adapter-pattern",children:"The Universal Adapter Pattern"}),"\n",(0,s.jsxs)(n.p,{children:["ai.matey uses the ",(0,s.jsx)(n.strong,{children:"Adapter Pattern"})," to provide a universal interface for AI APIs:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Your Application                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Frontend Adapter (Input Format)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Intermediate Representation (IR) - Universal        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Middleware Stack                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Backend Adapter (AI Provider)                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                          \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     AI Provider API                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Key Insight:"})," The Intermediate Representation (IR) is the secret sauce that makes everything work."]}),"\n",(0,s.jsx)(n.h2,{id:"intermediate-representation-ir",children:"Intermediate Representation (IR)"}),"\n",(0,s.jsx)(n.p,{children:"The IR is a provider-agnostic format for representing AI requests and responses."}),"\n",(0,s.jsx)(n.h3,{id:"design-principles",children:"Design Principles"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Provider-Agnostic"}),": Works with any AI provider"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Extensible"}),": Can add new fields without breaking compatibility"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type-Safe"}),": Full TypeScript support"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Stream-Friendly"}),": First-class streaming support"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Semantic Drift Tracking"}),": Captures lossy conversions"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"ir-message-format",children:"IR Message Format"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface IRMessage {\n  role: 'system' | 'user' | 'assistant' | 'tool';\n  content: string | IRContent[];\n  name?: string;\n  tool_calls?: IRToolCall[];\n  tool_call_id?: string;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"ir-request-format",children:"IR Request Format"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface IRChatCompletionRequest {\n  model: string;\n  messages: IRMessage[];\n  temperature?: number;\n  max_tokens?: number;\n  top_p?: number;\n  top_k?: number;\n  stream?: boolean;\n  stop?: string | string[];\n  tools?: IRTool[];\n  metadata?: Record<string, unknown>;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"ir-response-format",children:"IR Response Format"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface IRChatCompletionResponse {\n  id: string;\n  object: 'chat.completion';\n  created: number;\n  model: string;\n  choices: IRChoice[];\n  usage?: IRUsage;\n  metadata?: Record<string, unknown>;\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"frontend-adapters",children:"Frontend Adapters"}),"\n",(0,s.jsx)(n.p,{children:"Frontend adapters translate from a specific API format to IR."}),"\n",(0,s.jsx)(n.h3,{id:"interface",children:"Interface"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface FrontendAdapter {\n  name: string;\n\n  // Convert frontend format \u2192 IR\n  toIR(request: FrontendRequest): IRChatCompletionRequest;\n\n  // Convert IR \u2192 frontend format\n  fromIR(response: IRChatCompletionResponse): FrontendResponse;\n\n  // Streaming support (optional)\n  fromIRStream?(\n    stream: AsyncIterable<IRChatCompletionChunk>\n  ): AsyncIterable<FrontendChunk>;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"implementation-example",children:"Implementation Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class OpenAIFrontendAdapter implements FrontendAdapter {\n  name = 'openai';\n\n  toIR(request: OpenAIChatRequest): IRChatCompletionRequest {\n    return {\n      model: request.model,\n      messages: request.messages.map(msg => ({\n        role: msg.role,\n        content: msg.content\n      })),\n      temperature: request.temperature,\n      max_tokens: request.max_tokens,\n      // ... map all fields\n    };\n  }\n\n  fromIR(response: IRChatCompletionResponse): OpenAIChatResponse {\n    return {\n      id: response.id,\n      object: 'chat.completion',\n      created: response.created,\n      model: response.model,\n      choices: response.choices.map(choice => ({\n        index: choice.index,\n        message: {\n          role: choice.message.role,\n          content: choice.message.content\n        },\n        finish_reason: choice.finish_reason\n      })),\n      usage: response.usage\n    };\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"backend-adapters",children:"Backend Adapters"}),"\n",(0,s.jsx)(n.p,{children:"Backend adapters translate from IR to provider-specific API calls."}),"\n",(0,s.jsx)(n.h3,{id:"interface-1",children:"Interface"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface BackendAdapter {\n  name: string;\n\n  // Execute non-streaming request\n  chat(request: IRChatCompletionRequest): Promise<IRChatCompletionResponse>;\n\n  // Execute streaming request\n  chatStream(\n    request: IRChatCompletionRequest\n  ): AsyncIterable<IRChatCompletionChunk>;\n\n  // Health check (optional)\n  healthCheck?(): Promise<boolean>;\n\n  // Capabilities (optional)\n  capabilities?: IRCapabilities;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"implementation-example-1",children:"Implementation Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class AnthropicBackendAdapter implements BackendAdapter {\n  name = 'anthropic';\n  private client: Anthropic;\n\n  constructor(options: AnthropicOptions) {\n    this.client = new Anthropic({ apiKey: options.apiKey });\n  }\n\n  async chat(request: IRChatCompletionRequest): Promise<IRChatCompletionResponse> {\n    // Convert IR \u2192 Anthropic format\n    const anthropicRequest = this.toAnthropicFormat(request);\n\n    // Make API call\n    const anthropicResponse = await this.client.messages.create(anthropicRequest);\n\n    // Convert Anthropic format \u2192 IR\n    return this.toIRFormat(anthropicResponse);\n  }\n\n  async *chatStream(request: IRChatCompletionRequest) {\n    const anthropicRequest = this.toAnthropicFormat(request);\n\n    const stream = await this.client.messages.create({\n      ...anthropicRequest,\n      stream: true\n    });\n\n    for await (const chunk of stream) {\n      yield this.chunkToIR(chunk);\n    }\n  }\n\n  private toAnthropicFormat(request: IRChatCompletionRequest): MessageCreateParams {\n    // Extract system message (separate in Anthropic)\n    const systemMessages = request.messages.filter(m => m.role === 'system');\n    const system = systemMessages.map(m => m.content).join('\\n');\n\n    return {\n      model: this.mapModel(request.model),\n      max_tokens: request.max_tokens || 1024,\n      messages: request.messages\n        .filter(m => m.role !== 'system')\n        .map(m => ({\n          role: m.role === 'user' ? 'user' : 'assistant',\n          content: m.content\n        })),\n      system: system || undefined,\n      temperature: request.temperature,\n      top_p: request.top_p,\n      stop_sequences: Array.isArray(request.stop) ? request.stop : request.stop ? [request.stop] : undefined\n    };\n  }\n\n  private toIRFormat(response: Message): IRChatCompletionResponse {\n    return {\n      id: response.id,\n      object: 'chat.completion',\n      created: Date.now(),\n      model: response.model,\n      choices: [{\n        index: 0,\n        message: {\n          role: 'assistant',\n          content: response.content[0].type === 'text' ? response.content[0].text : ''\n        },\n        finish_reason: response.stop_reason === 'end_turn' ? 'stop' : response.stop_reason\n      }],\n      usage: {\n        prompt_tokens: response.usage.input_tokens,\n        completion_tokens: response.usage.output_tokens,\n        total_tokens: response.usage.input_tokens + response.usage.output_tokens\n      }\n    };\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"bridge-architecture",children:"Bridge Architecture"}),"\n",(0,s.jsx)(n.p,{children:"The Bridge connects frontend and backend adapters."}),"\n",(0,s.jsx)(n.h3,{id:"core-implementation",children:"Core Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class Bridge {\n  private middleware: Middleware[] = [];\n\n  constructor(\n    private frontendAdapter: FrontendAdapter,\n    private backendAdapter: BackendAdapter\n  ) {}\n\n  async chat(request: any): Promise<any> {\n    // 1. Convert frontend format \u2192 IR\n    const irRequest = this.frontendAdapter.toIR(request);\n\n    // 2. Execute middleware chain\n    const irResponse = await this.executeMiddleware(irRequest);\n\n    // 3. Convert IR \u2192 frontend format\n    return this.frontendAdapter.fromIR(irResponse);\n  }\n\n  private async executeMiddleware(\n    request: IRChatCompletionRequest\n  ): Promise<IRChatCompletionResponse> {\n    // Build middleware chain\n    const execute = this.middleware.reduceRight(\n      (next, middleware) => {\n        return async (req: IRChatCompletionRequest) => {\n          return middleware.execute(req, next);\n        };\n      },\n      // Final handler: call backend\n      async (req: IRChatCompletionRequest) => {\n        return this.backendAdapter.chat(req);\n      }\n    );\n\n    return execute(request);\n  }\n\n  use(middleware: Middleware) {\n    this.middleware.push(middleware);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"router-architecture",children:"Router Architecture"}),"\n",(0,s.jsx)(n.p,{children:"The Router extends Bridge to support multiple backends."}),"\n",(0,s.jsx)(n.h3,{id:"core-implementation-1",children:"Core Implementation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class Router extends Bridge {\n  private backends: BackendAdapter[];\n  private strategy: RoutingStrategy;\n  private currentIndex = 0;\n\n  constructor(\n    frontendAdapter: FrontendAdapter,\n    options: RouterOptions\n  ) {\n    // Router doesn't have a single backend\n    super(frontendAdapter, options.backends[0]);\n\n    this.backends = options.backends;\n    this.strategy = options.strategy;\n  }\n\n  protected async executeBackend(\n    request: IRChatCompletionRequest\n  ): Promise<IRChatCompletionResponse> {\n    // Select backend based on strategy\n    const backendIndex = this.selectBackend(request);\n    const backend = this.backends[backendIndex];\n\n    try {\n      return await backend.chat(request);\n    } catch (error) {\n      // Fallback to next backend if configured\n      if (this.options.fallbackOnError && backendIndex < this.backends.length - 1) {\n        this.emit('backend:failed', { backend: backend.name, error });\n        return this.executeBackend(request); // Recursive fallback\n      }\n      throw error;\n    }\n  }\n\n  private selectBackend(request: IRChatCompletionRequest): number {\n    switch (this.strategy) {\n      case 'round-robin':\n        const index = this.currentIndex;\n        this.currentIndex = (this.currentIndex + 1) % this.backends.length;\n        return index;\n\n      case 'priority':\n        return 0; // Always use first (will fallback if it fails)\n\n      case 'random':\n        return Math.floor(Math.random() * this.backends.length);\n\n      case 'custom':\n        return this.options.customStrategy(request, this.backends);\n\n      default:\n        return 0;\n    }\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"middleware-system",children:"Middleware System"}),"\n",(0,s.jsxs)(n.p,{children:["Middleware intercepts requests/responses using the ",(0,s.jsx)(n.strong,{children:"Chain of Responsibility"})," pattern."]}),"\n",(0,s.jsx)(n.h3,{id:"middleware-interface",children:"Middleware Interface"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface Middleware {\n  name: string;\n  execute(\n    request: IRChatCompletionRequest,\n    next: (request: IRChatCompletionRequest) => Promise<IRChatCompletionResponse>\n  ): Promise<IRChatCompletionResponse>;\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"implementation-example-2",children:"Implementation Example"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export function createLoggingMiddleware(options: LoggingOptions): Middleware {\n  return {\n    name: 'logging',\n    async execute(request, next) {\n      const start = Date.now();\n\n      console.log('[INFO] Request:', {\n        model: request.model,\n        messages: request.messages.length\n      });\n\n      try {\n        const response = await next(request);\n\n        console.log('[INFO] Response:', {\n          duration: Date.now() - start,\n          tokens: response.usage?.total_tokens\n        });\n\n        return response;\n      } catch (error) {\n        console.error('[ERROR]', error.message);\n        throw error;\n      }\n    }\n  };\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"middleware-chain-execution",children:"Middleware Chain Execution"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// Middleware stack\nbridge.use(middleware1); // Outer\nbridge.use(middleware2); // Middle\nbridge.use(middleware3); // Inner\n\n// Execution flow:\n// Request  \u2192 middleware1 \u2192 middleware2 \u2192 middleware3 \u2192 Backend\n// Response \u2190 middleware1 \u2190 middleware2 \u2190 middleware3 \u2190 Backend\n"})}),"\n",(0,s.jsx)(n.h2,{id:"streaming-architecture",children:"Streaming Architecture"}),"\n",(0,s.jsxs)(n.p,{children:["Streaming uses ",(0,s.jsx)(n.strong,{children:"AsyncIterators"})," for real-time response delivery."]}),"\n",(0,s.jsx)(n.h3,{id:"streaming-flow",children:"Streaming Flow"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"async *chatStream(request: IRChatCompletionRequest) {\n  // 1. Convert to provider format\n  const providerRequest = this.toProviderFormat(request);\n\n  // 2. Get provider stream\n  const stream = await this.provider.stream(providerRequest);\n\n  // 3. Convert chunks to IR\n  for await (const providerChunk of stream) {\n    const irChunk = this.chunkToIR(providerChunk);\n    yield irChunk;\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"stream-consumption",children:"Stream Consumption"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const stream = await bridge.chatStream(request);\n\nfor await (const chunk of stream) {\n  const content = chunk.choices?.[0]?.delta?.content;\n  if (content) {\n    process.stdout.write(content);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"type-system",children:"Type System"}),"\n",(0,s.jsx)(n.h3,{id:"type-hierarchy",children:"Type Hierarchy"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// Base types\ntypes/\n\u251c\u2500\u2500 ir-request.ts       # IRChatCompletionRequest\n\u251c\u2500\u2500 ir-response.ts      # IRChatCompletionResponse\n\u251c\u2500\u2500 ir-chunk.ts         # IRChatCompletionChunk\n\u251c\u2500\u2500 ir-message.ts       # IRMessage, IRContent\n\u251c\u2500\u2500 ir-tool.ts          # IRTool, IRToolCall\n\u251c\u2500\u2500 frontend.ts         # FrontendAdapter interface\n\u251c\u2500\u2500 backend.ts          # BackendAdapter interface\n\u2514\u2500\u2500 middleware.ts       # Middleware interface\n"})}),"\n",(0,s.jsx)(n.h3,{id:"type-safety",children:"Type Safety"}),"\n",(0,s.jsx)(n.p,{children:"All conversions are type-safe:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// Frontend adapter\ntoIR(request: OpenAIChatRequest): IRChatCompletionRequest {\n  // TypeScript ensures all required IR fields are present\n}\n\n// Backend adapter\nchat(request: IRChatCompletionRequest): Promise<IRChatCompletionResponse> {\n  // TypeScript ensures correct IR types\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,s.jsx)(n.h3,{id:"error-hierarchy",children:"Error Hierarchy"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class BridgeError extends Error {\n  constructor(\n    message: string,\n    public code: string,\n    public details?: unknown\n  ) {\n    super(message);\n    this.name = 'BridgeError';\n  }\n}\n\n// Specific error types\nexport class ValidationError extends BridgeError {\n  constructor(message: string, details?: unknown) {\n    super(message, 'VALIDATION_ERROR', details);\n  }\n}\n\nexport class NetworkError extends BridgeError {\n  constructor(message: string, details?: unknown) {\n    super(message, 'NETWORK_ERROR', details);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"error-propagation",children:"Error Propagation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"try {\n  const response = await bridge.chat(request);\n} catch (error) {\n  if (error instanceof ValidationError) {\n    // Handle validation errors\n  } else if (error instanceof NetworkError) {\n    // Handle network errors\n  } else {\n    // Handle unknown errors\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsx)(n.h3,{id:"async-iterator-efficiency",children:"Async Iterator Efficiency"}),"\n",(0,s.jsx)(n.p,{children:"Streams use async generators for efficient memory usage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"async *chatStream(request) {\n  // Chunks are processed one at a time\n  // No buffering of entire response\n  for await (const chunk of providerStream) {\n    yield processChunk(chunk);\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"middleware-performance",children:"Middleware Performance"}),"\n",(0,s.jsx)(n.p,{children:"Middleware executes sequentially. Keep middleware fast:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"// \u2705 Good - fast synchronous operation\nasync execute(request, next) {\n  const start = Date.now();\n  const response = await next(request);\n  console.log('Duration:', Date.now() - start);\n  return response;\n}\n\n// \u274c Bad - slow blocking operation\nasync execute(request, next) {\n  await heavyComputation(); // Blocks all requests!\n  return next(request);\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"testing-architecture",children:"Testing Architecture"}),"\n",(0,s.jsx)(n.h3,{id:"mock-adapters",children:"Mock Adapters"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"export class MockBackendAdapter implements BackendAdapter {\n  name = 'mock';\n  private responses = new Map<string, any>();\n\n  setResponse(key: string, response: any) {\n    this.responses.set(key, response);\n  }\n\n  async chat(request: IRChatCompletionRequest) {\n    const key = JSON.stringify(request.messages);\n    return this.responses.get(key) || this.defaultResponse();\n  }\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"integration-tests",children:"Integration Tests"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"describe('OpenAI \u2192 Anthropic Integration', () => {\n  it('should work end-to-end', async () => {\n    const bridge = new Bridge(\n      new OpenAIFrontendAdapter(),\n      new AnthropicBackendAdapter({ apiKey })\n    );\n\n    const response = await bridge.chat({\n      model: 'gpt-4',\n      messages: [{ role: 'user', content: 'Hello' }]\n    });\n\n    expect(response.choices[0].message.content).toBeTruthy();\n  });\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"design-patterns-used",children:"Design Patterns Used"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Adapter Pattern"}),": Frontend/backend adapters"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Chain of Responsibility"}),": Middleware execution"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Strategy Pattern"}),": Routing strategies"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Factory Pattern"}),": Middleware creators"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Observer Pattern"}),": Router events"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Iterator Pattern"}),": Streaming with async generators"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/contributing/development",children:"Development Guide"})," - Set up your environment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"/contributing",children:"Contributing Guide"})," - Make your first contribution"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Understanding the architecture helps you contribute effectively!"})," \ud83c\udfd7\ufe0f"]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}}}]);