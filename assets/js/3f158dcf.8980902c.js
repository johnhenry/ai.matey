"use strict";(globalThis.webpackChunkai_matey_docs=globalThis.webpackChunkai_matey_docs||[]).push([[8469],{1184:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>t});var r=i(4041);const l={},s=r.createContext(l);function d(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:d(e.components),r.createElement(s.Provider,{value:n},e.children)}},4279:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>t,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"packages/backend","title":"ai.matey.backend","description":"Backend adapters connect to AI provider APIs. Switch providers without changing your application code - just swap the backend adapter.","source":"@site/docs/packages/backend.md","sourceDirName":"packages","slug":"/packages/backend","permalink":"/ai.matey/packages/backend","draft":false,"unlisted":false,"editUrl":"https://github.com/johnhenry/ai.matey/tree/main/packages/ai.matey.docs/docs/packages/backend.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4}}');var l=i(1085),s=i(1184);const d={sidebar_position:4},t="ai.matey.backend",a={},c=[{value:"Installation",id:"installation",level:2},{value:"Overview",id:"overview",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"OpenAI Backend",id:"openai-backend",level:2},{value:"Installation",id:"installation-1",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Available Models",id:"available-models",level:3},{value:"Features",id:"features",level:3},{value:"Pricing (per 1M tokens)",id:"pricing-per-1m-tokens",level:3},{value:"Anthropic Backend",id:"anthropic-backend",level:2},{value:"Installation",id:"installation-2",level:3},{value:"Configuration",id:"configuration-1",level:3},{value:"Available Models",id:"available-models-1",level:3},{value:"Features",id:"features-1",level:3},{value:"Pricing (per 1M tokens)",id:"pricing-per-1m-tokens-1",level:3},{value:"Google Gemini Backend",id:"google-gemini-backend",level:2},{value:"Installation",id:"installation-3",level:3},{value:"Configuration",id:"configuration-2",level:3},{value:"Available Models",id:"available-models-2",level:3},{value:"Features",id:"features-2",level:3},{value:"Pricing (per 1M tokens)",id:"pricing-per-1m-tokens-2",level:3},{value:"Groq Backend",id:"groq-backend",level:2},{value:"Installation",id:"installation-4",level:3},{value:"Configuration",id:"configuration-3",level:3},{value:"Available Models",id:"available-models-3",level:3},{value:"Features",id:"features-3",level:3},{value:"Pricing",id:"pricing",level:3},{value:"DeepSeek Backend",id:"deepseek-backend",level:2},{value:"Installation",id:"installation-5",level:3},{value:"Configuration",id:"configuration-4",level:3},{value:"Available Models",id:"available-models-4",level:3},{value:"Features",id:"features-4",level:3},{value:"Pricing (per 1M tokens)",id:"pricing-per-1m-tokens-3",level:3},{value:"Ollama Backend",id:"ollama-backend",level:2},{value:"Installation",id:"installation-6",level:3},{value:"Configuration",id:"configuration-5",level:3},{value:"Available Models",id:"available-models-5",level:3},{value:"Features",id:"features-5",level:3},{value:"Setup",id:"setup",level:3},{value:"More Providers",id:"more-providers",level:2},{value:"Cohere",id:"cohere",level:3},{value:"Mistral",id:"mistral",level:3},{value:"Perplexity",id:"perplexity",level:3},{value:"Together AI",id:"together-ai",level:3},{value:"Provider Comparison",id:"provider-comparison",level:2},{value:"By Use Case",id:"by-use-case",level:3},{value:"Best for Production",id:"best-for-production",level:4},{value:"Best for Cost Optimization",id:"best-for-cost-optimization",level:4},{value:"Best for Speed",id:"best-for-speed",level:4},{value:"Best for Privacy",id:"best-for-privacy",level:4},{value:"Feature Matrix",id:"feature-matrix",level:3},{value:"Switching Providers",id:"switching-providers",level:2},{value:"Simple Switch",id:"simple-switch",level:3},{value:"Environment-Based",id:"environment-based",level:3},{value:"Multi-Provider Fallback",id:"multi-provider-fallback",level:3},{value:"Cost Optimization",id:"cost-optimization",level:2},{value:"Route by Complexity",id:"route-by-complexity",level:3},{value:"Provider-Specific Features",id:"provider-specific-features",level:2},{value:"OpenAI: JSON Mode",id:"openai-json-mode",level:3},{value:"Anthropic: Extended Context",id:"anthropic-extended-context",level:3},{value:"Gemini: Grounding",id:"gemini-grounding",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"1. Use Environment Variables",id:"1-use-environment-variables",level:3},{value:"2. Set Timeouts",id:"2-set-timeouts",level:3},{value:"3. Handle Errors",id:"3-handle-errors",level:3},{value:"4. Monitor Costs",id:"4-monitor-costs",level:3},{value:"See Also",id:"see-also",level:2}];function o(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"aimateybackend",children:"ai.matey.backend"})}),"\n",(0,l.jsx)(n.p,{children:"Backend adapters connect to AI provider APIs. Switch providers without changing your application code - just swap the backend adapter."}),"\n",(0,l.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"npm install ai.matey.backend\n"})}),"\n",(0,l.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,l.jsx)(n.p,{children:"Backend adapters translate ai.matey's Intermediate Representation (IR) into provider-specific API calls. This allows you to switch AI providers without changing your application code."}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Supported Providers (24+):"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"OpenAI (GPT-4, GPT-3.5)"}),"\n",(0,l.jsx)(n.li,{children:"Anthropic (Claude 3.5 Sonnet, Opus, Haiku)"}),"\n",(0,l.jsx)(n.li,{children:"Google (Gemini 1.5 Pro, Flash)"}),"\n",(0,l.jsx)(n.li,{children:"Groq (Llama 3, Mixtral)"}),"\n",(0,l.jsx)(n.li,{children:"DeepSeek (V3, Chat)"}),"\n",(0,l.jsx)(n.li,{children:"Ollama (Local models)"}),"\n",(0,l.jsx)(n.li,{children:"Cohere, Mistral, Perplexity, Together AI, and more!"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { Bridge } from 'ai.matey.core';\nimport { OpenAIFrontendAdapter } from 'ai.matey.frontend/openai';\nimport { AnthropicBackendAdapter } from 'ai.matey.backend/anthropic';\n\nconst bridge = new Bridge(\n  new OpenAIFrontendAdapter(),\n  new AnthropicBackendAdapter({\n    apiKey: process.env.ANTHROPIC_API_KEY\n  })\n);\n\n// Write in OpenAI format, execute with Claude\nconst response = await bridge.chat({\n  model: 'gpt-4',\n  messages: [{ role: 'user', content: 'Hello!' }]\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"openai-backend",children:"OpenAI Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use OpenAI's GPT models."}),"\n",(0,l.jsx)(n.h3,{id:"installation-1",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { OpenAIBackendAdapter } from 'ai.matey.backend/openai';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new OpenAIBackendAdapter({\n  apiKey: process.env.OPENAI_API_KEY, // Required\n  baseURL: 'https://api.openai.com/v1', // Optional\n  organization: 'org-xxx', // Optional\n  timeout: 60000, // Optional (default: 60s)\n  maxRetries: 3 // Optional (default: 2)\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models",children:"Available Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"GPT-4 Turbo"}),": ",(0,l.jsx)(n.code,{children:"gpt-4-turbo"}),", ",(0,l.jsx)(n.code,{children:"gpt-4-turbo-preview"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"GPT-4"}),": ",(0,l.jsx)(n.code,{children:"gpt-4"}),", ",(0,l.jsx)(n.code,{children:"gpt-4-0613"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"GPT-3.5 Turbo"}),": ",(0,l.jsx)(n.code,{children:"gpt-3.5-turbo"}),", ",(0,l.jsx)(n.code,{children:"gpt-3.5-turbo-16k"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"GPT-4 Vision"}),": ",(0,l.jsx)(n.code,{children:"gpt-4-vision-preview"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Function calling"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Vision (GPT-4 Vision)"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 JSON mode"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Seed for reproducibility"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"pricing-per-1m-tokens",children:"Pricing (per 1M tokens)"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Input"}),(0,l.jsx)(n.th,{children:"Output"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"GPT-4 Turbo"}),(0,l.jsx)(n.td,{children:"$10"}),(0,l.jsx)(n.td,{children:"$30"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"GPT-4"}),(0,l.jsx)(n.td,{children:"$30"}),(0,l.jsx)(n.td,{children:"$60"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"GPT-3.5 Turbo"}),(0,l.jsx)(n.td,{children:"$0.50"}),(0,l.jsx)(n.td,{children:"$1.50"})]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"anthropic-backend",children:"Anthropic Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use Anthropic's Claude models."}),"\n",(0,l.jsx)(n.h3,{id:"installation-2",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { AnthropicBackendAdapter } from 'ai.matey.backend/anthropic';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration-1",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new AnthropicBackendAdapter({\n  apiKey: process.env.ANTHROPIC_API_KEY, // Required\n  baseURL: 'https://api.anthropic.com', // Optional\n  timeout: 60000 // Optional\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models-1",children:"Available Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Claude 3.5 Sonnet"}),": ",(0,l.jsx)(n.code,{children:"claude-3-5-sonnet-20241022"})," (Latest, most capable)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Claude 3 Opus"}),": ",(0,l.jsx)(n.code,{children:"claude-3-opus-20240229"})," (Highest intelligence)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Claude 3 Sonnet"}),": ",(0,l.jsx)(n.code,{children:"claude-3-sonnet-20240229"})," (Balanced)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Claude 3 Haiku"}),": ",(0,l.jsx)(n.code,{children:"claude-3-haiku-20240307"})," (Fastest, cheapest)"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features-1",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Tool use"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Vision"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 200K context window"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 System prompts"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"pricing-per-1m-tokens-1",children:"Pricing (per 1M tokens)"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Input"}),(0,l.jsx)(n.th,{children:"Output"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Claude 3.5 Sonnet"}),(0,l.jsx)(n.td,{children:"$3"}),(0,l.jsx)(n.td,{children:"$15"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Claude 3 Opus"}),(0,l.jsx)(n.td,{children:"$15"}),(0,l.jsx)(n.td,{children:"$75"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Claude 3 Sonnet"}),(0,l.jsx)(n.td,{children:"$3"}),(0,l.jsx)(n.td,{children:"$15"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Claude 3 Haiku"}),(0,l.jsx)(n.td,{children:"$0.25"}),(0,l.jsx)(n.td,{children:"$1.25"})]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"google-gemini-backend",children:"Google Gemini Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use Google's Gemini models."}),"\n",(0,l.jsx)(n.h3,{id:"installation-3",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { GeminiBackendAdapter } from 'ai.matey.backend/gemini';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration-2",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new GeminiBackendAdapter({\n  apiKey: process.env.GEMINI_API_KEY, // Required\n  baseURL: 'https://generativelanguage.googleapis.com', // Optional\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models-2",children:"Available Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemini 1.5 Pro"}),": ",(0,l.jsx)(n.code,{children:"gemini-1.5-pro-latest"})," (Most capable)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemini 1.5 Flash"}),": ",(0,l.jsx)(n.code,{children:"gemini-1.5-flash-latest"})," (Fast, efficient)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemini 1.0 Pro"}),": ",(0,l.jsx)(n.code,{children:"gemini-1.0-pro"})," (Previous generation)"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features-2",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Function calling"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Native multi-modal (vision, audio)"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 2M token context (Pro)"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Grounding with Google Search"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"pricing-per-1m-tokens-2",children:"Pricing (per 1M tokens)"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Input"}),(0,l.jsx)(n.th,{children:"Output"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Gemini 1.5 Pro"}),(0,l.jsx)(n.td,{children:"$3.50"}),(0,l.jsx)(n.td,{children:"$10.50"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Gemini 1.5 Flash"}),(0,l.jsx)(n.td,{children:"$0.35"}),(0,l.jsx)(n.td,{children:"$1.05"})]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"groq-backend",children:"Groq Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use Groq's ultra-fast inference."}),"\n",(0,l.jsx)(n.h3,{id:"installation-4",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { GroqBackendAdapter } from 'ai.matey.backend/groq';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration-3",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new GroqBackendAdapter({\n  apiKey: process.env.GROQ_API_KEY // Required\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models-3",children:"Available Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Llama 3"}),": ",(0,l.jsx)(n.code,{children:"llama3-70b-8192"}),", ",(0,l.jsx)(n.code,{children:"llama3-8b-8192"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Mixtral"}),": ",(0,l.jsx)(n.code,{children:"mixtral-8x7b-32768"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemma"}),": ",(0,l.jsx)(n.code,{children:"gemma-7b-it"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features-3",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsxs)(n.li,{children:["\u2705 ",(0,l.jsx)(n.strong,{children:"Ultra-fast"})," (500+ tokens/sec)"]}),"\n",(0,l.jsx)(n.li,{children:"\u26a0\ufe0f Limited tool support"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"pricing",children:"Pricing"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Free tier available!"})," Very cost-effective for high-throughput use cases."]}),"\n",(0,l.jsx)(n.h2,{id:"deepseek-backend",children:"DeepSeek Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use DeepSeek's cost-effective models."}),"\n",(0,l.jsx)(n.h3,{id:"installation-5",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { DeepSeekBackendAdapter } from 'ai.matey.backend/deepseek';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration-4",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new DeepSeekBackendAdapter({\n  apiKey: process.env.DEEPSEEK_API_KEY // Required\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models-4",children:"Available Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"DeepSeek V3"}),": ",(0,l.jsx)(n.code,{children:"deepseek-chat"})," (Latest)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"DeepSeek Coder"}),": ",(0,l.jsx)(n.code,{children:"deepseek-coder"})," (Code specialist)"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features-4",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Competitive quality"}),"\n",(0,l.jsxs)(n.li,{children:["\u2705 ",(0,l.jsx)(n.strong,{children:"Very low cost"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"pricing-per-1m-tokens-3",children:"Pricing (per 1M tokens)"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Input"}),(0,l.jsx)(n.th,{children:"Output"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"DeepSeek Chat"}),(0,l.jsx)(n.td,{children:"$0.14"}),(0,l.jsx)(n.td,{children:"$0.28"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"DeepSeek Coder"}),(0,l.jsx)(n.td,{children:"$0.14"}),(0,l.jsx)(n.td,{children:"$0.28"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Up to 95% cheaper than GPT-4!"})}),"\n",(0,l.jsx)(n.h2,{id:"ollama-backend",children:"Ollama Backend"}),"\n",(0,l.jsx)(n.p,{children:"Use local open-source models."}),"\n",(0,l.jsx)(n.h3,{id:"installation-6",children:"Installation"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { OllamaBackendAdapter } from 'ai.matey.backend/ollama';\n"})}),"\n",(0,l.jsx)(n.h3,{id:"configuration-5",children:"Configuration"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new OllamaBackendAdapter({\n  baseURL: 'http://localhost:11434', // Optional (default)\n  timeout: 120000 // Optional (2 min for local inference)\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"available-models-5",children:"Available Models"}),"\n",(0,l.jsx)(n.p,{children:"Any model supported by Ollama:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Llama 3.2"}),": ",(0,l.jsx)(n.code,{children:"llama3.2"}),", ",(0,l.jsx)(n.code,{children:"llama3.2:70b"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Mistral"}),": ",(0,l.jsx)(n.code,{children:"mistral"}),", ",(0,l.jsx)(n.code,{children:"mistral-nemo"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Qwen"}),": ",(0,l.jsx)(n.code,{children:"qwen2.5:72b"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemma"}),": ",(0,l.jsx)(n.code,{children:"gemma2"})]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Phi"}),": ",(0,l.jsx)(n.code,{children:"phi3"})]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"features-5",children:"Features"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"\u2705 Chat completions"}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Streaming"}),"\n",(0,l.jsxs)(n.li,{children:["\u2705 ",(0,l.jsx)(n.strong,{children:"100% local"})," (no API costs)"]}),"\n",(0,l.jsx)(n.li,{children:"\u2705 Privacy (data never leaves your machine)"}),"\n",(0,l.jsx)(n.li,{children:"\u26a0\ufe0f Slower than cloud providers"}),"\n",(0,l.jsx)(n.li,{children:"\u26a0\ufe0f Limited tool support (model-dependent)"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"setup",children:"Setup"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["Install Ollama: ",(0,l.jsx)(n.a,{href:"https://ollama.ai",children:"https://ollama.ai"})]}),"\n",(0,l.jsxs)(n.li,{children:["Pull a model: ",(0,l.jsx)(n.code,{children:"ollama pull llama3.2"})]}),"\n",(0,l.jsx)(n.li,{children:"Use with ai.matey:"}),"\n"]}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const bridge = new Bridge(\n  new OpenAIFrontendAdapter(),\n  new OllamaBackendAdapter()\n);\n\nconst response = await bridge.chat({\n  model: 'llama3.2',\n  messages: [{ role: 'user', content: 'Hello!' }]\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"more-providers",children:"More Providers"}),"\n",(0,l.jsx)(n.h3,{id:"cohere",children:"Cohere"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { CohereBackendAdapter } from 'ai.matey.backend/cohere';\n\nconst backend = new CohereBackendAdapter({\n  apiKey: process.env.COHERE_API_KEY\n});\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Models:"})," ",(0,l.jsx)(n.code,{children:"command-r-plus"}),", ",(0,l.jsx)(n.code,{children:"command-r"}),", ",(0,l.jsx)(n.code,{children:"command"})]}),"\n",(0,l.jsx)(n.h3,{id:"mistral",children:"Mistral"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { MistralBackendAdapter } from 'ai.matey.backend/mistral';\n\nconst backend = new MistralBackendAdapter({\n  apiKey: process.env.MISTRAL_API_KEY\n});\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Models:"})," ",(0,l.jsx)(n.code,{children:"mistral-large-latest"}),", ",(0,l.jsx)(n.code,{children:"mistral-medium-latest"}),", ",(0,l.jsx)(n.code,{children:"mistral-small-latest"})]}),"\n",(0,l.jsx)(n.h3,{id:"perplexity",children:"Perplexity"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { PerplexityBackendAdapter } from 'ai.matey.backend/perplexity';\n\nconst backend = new PerplexityBackendAdapter({\n  apiKey: process.env.PERPLEXITY_API_KEY\n});\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Models:"})," ",(0,l.jsx)(n.code,{children:"llama-3.1-sonar-large"}),", ",(0,l.jsx)(n.code,{children:"llama-3.1-sonar-small"})]}),"\n",(0,l.jsx)(n.h3,{id:"together-ai",children:"Together AI"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { TogetherBackendAdapter } from 'ai.matey.backend/together';\n\nconst backend = new TogetherBackendAdapter({\n  apiKey: process.env.TOGETHER_API_KEY\n});\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Models:"})," Wide selection of open-source models"]}),"\n",(0,l.jsx)(n.h2,{id:"provider-comparison",children:"Provider Comparison"}),"\n",(0,l.jsx)(n.h3,{id:"by-use-case",children:"By Use Case"}),"\n",(0,l.jsx)(n.h4,{id:"best-for-production",children:"Best for Production"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"OpenAI"})," - Most reliable, widely tested"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Anthropic"})," - Excellent quality, large context"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Google Gemini"})," - Strong multi-modal capabilities"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"best-for-cost-optimization",children:"Best for Cost Optimization"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"DeepSeek"})," - Cheapest cloud option"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Ollama"})," - Free (local)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Groq"})," - Generous free tier"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"best-for-speed",children:"Best for Speed"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Groq"})," - 500+ tokens/sec"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Gemini Flash"})," - Very fast"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Claude Haiku"})," - Fast cloud model"]}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"best-for-privacy",children:"Best for Privacy"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Ollama"})," - 100% local"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"LM Studio"})," - Local with GUI"]}),"\n",(0,l.jsx)(n.li,{children:"Self-hosted options"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"feature-matrix",children:"Feature Matrix"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Provider"}),(0,l.jsx)(n.th,{children:"Streaming"}),(0,l.jsx)(n.th,{children:"Tools"}),(0,l.jsx)(n.th,{children:"Vision"}),(0,l.jsx)(n.th,{children:"Context"}),(0,l.jsx)(n.th,{children:"Speed"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"OpenAI"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"128K"}),(0,l.jsx)(n.td,{children:"Fast"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Anthropic"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"200K"}),(0,l.jsx)(n.td,{children:"Fast"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Gemini"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"2M"}),(0,l.jsx)(n.td,{children:"Fast"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Groq"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u26a0\ufe0f"}),(0,l.jsx)(n.td,{children:"\u274c"}),(0,l.jsx)(n.td,{children:"32K"}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Very Fast"})})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"DeepSeek"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u274c"}),(0,l.jsx)(n.td,{children:"64K"}),(0,l.jsx)(n.td,{children:"Medium"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Ollama"}),(0,l.jsx)(n.td,{children:"\u2705"}),(0,l.jsx)(n.td,{children:"\u26a0\ufe0f"}),(0,l.jsx)(n.td,{children:"\u26a0\ufe0f"}),(0,l.jsx)(n.td,{children:"Varies"}),(0,l.jsx)(n.td,{children:"Slow"})]})]})]}),"\n",(0,l.jsx)(n.h2,{id:"switching-providers",children:"Switching Providers"}),"\n",(0,l.jsx)(n.h3,{id:"simple-switch",children:"Simple Switch"}),"\n",(0,l.jsx)(n.p,{children:"Change providers by only changing the backend:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"// Before: OpenAI\nconst bridge = new Bridge(\n  new OpenAIFrontendAdapter(),\n  new OpenAIBackendAdapter({ apiKey: openaiKey })\n);\n\n// After: Anthropic (only change backend!)\nconst bridge = new Bridge(\n  new OpenAIFrontendAdapter(), // Same frontend\n  new AnthropicBackendAdapter({ apiKey: anthropicKey })\n);\n"})}),"\n",(0,l.jsx)(n.h3,{id:"environment-based",children:"Environment-Based"}),"\n",(0,l.jsx)(n.p,{children:"Use different providers for dev/prod:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = process.env.NODE_ENV === 'production'\n  ? new AnthropicBackendAdapter({ apiKey: process.env.ANTHROPIC_API_KEY })\n  : new OllamaBackendAdapter({ baseURL: 'http://localhost:11434' });\n\nconst bridge = new Bridge(new OpenAIFrontendAdapter(), backend);\n"})}),"\n",(0,l.jsx)(n.h3,{id:"multi-provider-fallback",children:"Multi-Provider Fallback"}),"\n",(0,l.jsx)(n.p,{children:"Use Router for automatic failover:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { Router } from 'ai.matey.core';\n\nconst router = new Router(new OpenAIFrontendAdapter(), {\n  backends: [\n    new AnthropicBackendAdapter({ apiKey: process.env.ANTHROPIC_API_KEY }),\n    new OpenAIBackendAdapter({ apiKey: process.env.OPENAI_API_KEY }),\n    new GroqBackendAdapter({ apiKey: process.env.GROQ_API_KEY })\n  ],\n  strategy: 'priority',\n  fallbackOnError: true\n});\n\n// Automatically tries Anthropic, then OpenAI, then Groq\nconst response = await router.chat({\n  model: 'gpt-4',\n  messages: [{ role: 'user', content: 'Hello!' }]\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"cost-optimization",children:"Cost Optimization"}),"\n",(0,l.jsx)(n.h3,{id:"route-by-complexity",children:"Route by Complexity"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const router = new Router(new OpenAIFrontendAdapter(), {\n  backends: [\n    new DeepSeekBackendAdapter({ apiKey: process.env.DEEPSEEK_API_KEY }), // Cheap\n    new GroqBackendAdapter({ apiKey: process.env.GROQ_API_KEY }),         // Fast\n    new OpenAIBackendAdapter({ apiKey: process.env.OPENAI_API_KEY }),     // Powerful\n    new AnthropicBackendAdapter({ apiKey: process.env.ANTHROPIC_API_KEY }) // Most capable\n  ],\n  strategy: 'custom',\n  customStrategy: (request) => {\n    const messageLength = JSON.stringify(request.messages).length;\n\n    if (messageLength < 100) return 0;  // DeepSeek: simple queries\n    if (messageLength < 500) return 1;  // Groq: moderate queries\n    if (messageLength < 2000) return 2; // OpenAI: complex queries\n    return 3; // Anthropic: very complex queries\n  }\n});\n"})}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Potential savings:"})," Up to 90% compared to always using GPT-4."]}),"\n",(0,l.jsx)(n.h2,{id:"provider-specific-features",children:"Provider-Specific Features"}),"\n",(0,l.jsx)(n.h3,{id:"openai-json-mode",children:"OpenAI: JSON Mode"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const bridge = new Bridge(\n  new OpenAIFrontendAdapter(),\n  new OpenAIBackendAdapter({ apiKey })\n);\n\nconst response = await bridge.chat({\n  model: 'gpt-4',\n  messages: [{ role: 'user', content: 'Return a user object' }],\n  response_format: { type: 'json_object' }\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"anthropic-extended-context",children:"Anthropic: Extended Context"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const bridge = new Bridge(\n  new OpenAIFrontendAdapter(),\n  new AnthropicBackendAdapter({ apiKey })\n);\n\n// Claude supports up to 200K tokens!\nconst longDocument = fs.readFileSync('long-doc.txt', 'utf-8');\n\nconst response = await bridge.chat({\n  model: 'claude-3-5-sonnet-20241022',\n  messages: [\n    { role: 'user', content: `Summarize this:\\n\\n${longDocument}` }\n  ]\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"gemini-grounding",children:"Gemini: Grounding"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const bridge = new Bridge(\n  new GeminiFrontendAdapter(),\n  new GeminiBackendAdapter({ apiKey })\n);\n\nconst response = await bridge.chat({\n  model: 'gemini-1.5-pro',\n  contents: [{ role: 'user', parts: [{ text: 'Latest AI news?' }] }],\n  tools: [{ google_search_retrieval: {} }] // Enable grounding\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,l.jsx)(n.h3,{id:"1-use-environment-variables",children:"1. Use Environment Variables"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new AnthropicBackendAdapter({\n  apiKey: process.env.ANTHROPIC_API_KEY // Don't hardcode!\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"2-set-timeouts",children:"2. Set Timeouts"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"const backend = new OpenAIBackendAdapter({\n  apiKey: process.env.OPENAI_API_KEY,\n  timeout: 30000 // 30 seconds\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"3-handle-errors",children:"3. Handle Errors"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"try {\n  const response = await bridge.chat(request);\n} catch (error) {\n  if (error.code === 'RATE_LIMIT_ERROR') {\n    console.log('Rate limited, waiting...');\n    await sleep(1000);\n  } else if (error.code === 'AUTH_ERROR') {\n    console.error('Invalid API key');\n  } else {\n    console.error('Error:', error.message);\n  }\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"4-monitor-costs",children:"4. Monitor Costs"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { createCostTrackingMiddleware } from 'ai.matey.middleware';\n\nbridge.use(createCostTrackingMiddleware({\n  budgetLimit: 100,\n  onBudgetExceeded: () => {\n    console.error('Daily budget exceeded!');\n  }\n}));\n"})}),"\n",(0,l.jsx)(n.h2,{id:"see-also",children:"See Also"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/packages/frontend",children:"Frontend Adapters"})," - Available input formats"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/packages/core",children:"Core Package"})," - Bridge and Router"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/packages/middleware",children:"Middleware"})," - Add logging, caching, etc."]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"/patterns",children:"Integration Patterns"})," - Production patterns"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.a,{href:"https://github.com/johnhenry/ai.matey/tree/main/packages/ai.matey.docs/examples/02-providers",children:"Examples on GitHub"})," - Provider examples"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(o,{...e})}):o(e)}}}]);